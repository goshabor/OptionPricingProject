{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8defcd19",
   "metadata": {},
   "source": [
    "# PINN\n",
    "\n",
    "This notebook is dedicated to the training of the Physics-Inspired-Neural-Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf76ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c288dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from PINN import train_PINN_ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad6df4",
   "metadata": {},
   "source": [
    "## Used variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2b6a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta_r = [0.10070984, 0.01024475, 0.03245518, 0.02578739]\n",
      "r0 = 0.0191672169145129\n"
     ]
    }
   ],
   "source": [
    "short_rate_params = pd.read_csv('/Users/goshabor/NTNU/9.Semester/TMA4500 – Fordypningsprosjekt/Code/CIRPlusPlusResults/short_rate_params.csv')\n",
    "\n",
    "r0 = float(short_rate_params['r0'].iloc[0])\n",
    "Theta_r = short_rate_params.iloc[0, 2:6].astype(float).to_list()\n",
    "Svensson_params = short_rate_params.iloc[0, 6:].astype(float).to_list()\n",
    "\n",
    "print(f'Theta_r = {Theta_r}')\n",
    "print(f'r0 = {r0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45ac5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths to store models\n",
    "filepath_histories = '/Users/goshabor/NTNU/9.Semester/TMA4500 – Fordypningsprosjekt/Code/PINNResults/TrainingHistories/'\n",
    "filepath_models = '/Users/goshabor/NTNU/9.Semester/TMA4500 – Fordypningsprosjekt/Code/PINNResults/TrainedModels/'\n",
    "\n",
    "histories_directory = Path(filepath_histories).expanduser()\n",
    "histories_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_directory = Path(filepath_models).expanduser()\n",
    "model_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8683671",
   "metadata": {},
   "source": [
    "## PINN Training using ADAM\n",
    "\n",
    "We now perform a weighted training of the PINN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d880c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ Training 4x512 weighted model ------------------------------------------------\n",
      "Phase 1/5 | lr=0.005 | 1/500 | Total loss=2537.568 | Interior loss=2.511 | Loss lower=4.174 | Loss upper=0.988 | Loss terminal=2529.895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m PINN_params = [input_dim, hidden_dim, num_layers, batch_boundary, batch_interior]\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#PINN training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m model, history = \u001b[43mtrain_PINN_ADAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrike_price\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrike_price\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_S\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_S\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTheta_r\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTheta_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_r\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_nu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_nu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_rho\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_rho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSvensson_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSvensson_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPINN_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPINN_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mepochs_per_phase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs_per_phase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_loss_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mboundary_loss_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m#saving histories and model for later evaluation\u001b[39;00m\n\u001b[32m     56\u001b[39m tag = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(num_layers-\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NTNU/9.Semester/TMA4500 – Fordypningsprosjekt/Code/PINNOptionPricing/PINN.py:396\u001b[39m, in \u001b[36mtrain_PINN_ADAM\u001b[39m\u001b[34m(strike_price, bounds_S, bounds_r, Theta_r, Svensson_params, bounds_nu, bounds_rho, bounds_time, PINN_params, epochs_per_phase, learning_rates, boundary_loss_weights, print_every)\u001b[39m\n\u001b[32m    394\u001b[39m optimizer.zero_grad()\n\u001b[32m    395\u001b[39m total_loss, loss_interior, loss_upper, loss_lower, loss_terminal = model.loss_total()\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m \u001b[43mtotal_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m optimizer.step()\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(epoch%print_every==\u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, epochs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#bounds_S\n",
    "strike_price = 50\n",
    "factor = 3\n",
    "S_min = 0.1*strike_price; S_max = factor*strike_price\n",
    "bounds_S = [S_min, S_max]\n",
    "\n",
    "#bounds r\n",
    "r_min = 0.01; r_max = 0.05\n",
    "bounds_r = [r_min, r_max]\n",
    "\n",
    "#bounds_nu\n",
    "nu_min = 0.03**2; nu_max = 0.5**2\n",
    "kappa_nu_min = 5e-1; kappa_nu_max = 5.0\n",
    "theta_nu_min = 0.05**2; theta_nu_max = 0.5**2\n",
    "sigma_nu_min = 1e-1; sigma_nu_max = 1.0\n",
    "\n",
    "bounds_nu = [[nu_min, nu_max], [kappa_nu_min, kappa_nu_max], [theta_nu_min, theta_nu_max], [sigma_nu_min, sigma_nu_max]]\n",
    "\n",
    "#bounds_rho\n",
    "rho_min = -1.0; rho_max = 1.0\n",
    "bounds_rho = [rho_min, rho_max]\n",
    "\n",
    "#bounds_time\n",
    "T_min = 0.0; T_max = 3.0\n",
    "bounds_time = [T_min, T_max]\n",
    "\n",
    "input_dim = 9\n",
    "hidden_dim_arr = [512]\n",
    "num_layers_arr = [5]\n",
    "\n",
    "batch_boundary = 5000\n",
    "batch_interior = 20000 \n",
    "\n",
    "#training related\n",
    "epochs_per_phase = [500, 1000, 1500, 2000, 2000] #1-500, 501-1500, 1501-3000, 3001-5000, 5001-7000\n",
    "learning_rates = [5e-3, 2e-3, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "results = [] #to store filepaths and model losses\n",
    "\n",
    "#boundary_loss_weights = [weights_interior, weights_lower, weights_upper, weights_terminal, weights_MC]\n",
    "boundary_loss_weights = [1, 1, 1, 1]\n",
    "\n",
    "### --- Weighted PINN Training ---\n",
    "for hidden_dim in hidden_dim_arr:\n",
    "    for num_layers in num_layers_arr:\n",
    "        print(f'------------------------------------------------ Training {int(num_layers-1)}x{hidden_dim} weighted model ------------------------------------------------')\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        PINN_params = [input_dim, hidden_dim, num_layers, batch_boundary, batch_interior]\n",
    "\n",
    "        #PINN training\n",
    "        model, history = train_PINN_ADAM(strike_price=strike_price, bounds_S=bounds_S, Theta_r=Theta_r, bounds_r=bounds_r, bounds_nu=bounds_nu, bounds_rho=bounds_rho, bounds_time=bounds_time, Svensson_params=Svensson_params, PINN_params=PINN_params, \n",
    "                                epochs_per_phase=epochs_per_phase, learning_rates=learning_rates, boundary_loss_weights=boundary_loss_weights, print_every=100)\n",
    "        \n",
    "        #saving histories and model for later evaluation\n",
    "        tag = f'{int(num_layers-1)}x{hidden_dim}'\n",
    "\n",
    "        histories_path = histories_directory / f'{tag}_{factor}x_2.xlsx'\n",
    "        ckpt_path = model_directory / f'{tag}_{factor}x_2.pt'\n",
    "\n",
    "        cols = ['phase', 'epoch', 'total loss', 'interior loss', 'loss lower', 'loss upper', 'terminal']\n",
    "        pd.DataFrame(history, columns=cols).to_excel(f'{histories_path}', index=False)\n",
    "\n",
    "        ckpt = {\n",
    "            'model_state': model.state_dict(),\n",
    "            'config': {\n",
    "                'PINN_params': PINN_params,\n",
    "                'bounds_S': bounds_S,\n",
    "                'bounds_r': bounds_r,\n",
    "                'bounds_nu': bounds_nu,\n",
    "                'bounds_rho': bounds_rho,\n",
    "                'bounds_time': bounds_time,\n",
    "                'Theta_r': Theta_r,\n",
    "                'Svensson_params': Svensson_params,\n",
    "                'strike_price': strike_price,\n",
    "                'boundary_loss_weights': boundary_loss_weights,\n",
    "                'dtype': str(next(model.parameters()).dtype), \n",
    "                'epochs': epochs_per_phase,\n",
    "                'lr': learning_rates\n",
    "            }\n",
    "        }\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "\n",
    "        final_total = float(history[-1][2]) if len(history) else float('nan')\n",
    "        results.append({\n",
    "            'tag': f'{int(num_layers-1)}x{hidden_dim}',\n",
    "            'final_total_loss': final_total,\n",
    "            'ckpt_path': ckpt_path,\n",
    "            'history_csv': histories_path\n",
    "        })\n",
    "\n",
    "        #freeing memory to avoid memory leak\n",
    "        del model, history\n",
    "        gc.collect()\n",
    "        \n",
    "        if torch.backends.mps.is_available():\n",
    "            torch.mps.empty_cache()\n",
    "        elif torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        elapsed_time_minutes = (start_time-end_time)/60\n",
    "\n",
    "        print(f'Model saved as {tag}_{factor}x_2.pt | Execution time: {abs(elapsed_time_minutes):.4f} minutes')\n",
    "        print(f'------------------------------------------ Finished training {tag} weighted model ------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93f4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
